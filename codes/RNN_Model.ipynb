{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-900b6f75ae95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb 18 18:50:22 2019\n",
    "\n",
    "@author: Eric\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from sklearn.preprocessing import normalize\n",
    "from eplusparser.eplusparser import parse\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def create_dataset(dataset,names,scaler,look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    \n",
    "    for i in range(3,len(names)):\n",
    "        if \"Setpoint\" in names[i][1] or \"Schedule\" in names[i][1] or \"Occupant\" in names[i][1] or \"Outdoor\" in names[i][1]:\n",
    "            dataX.append(dataset[1:,i])\n",
    "        \n",
    "        else:\n",
    "            dataX.append(dataset[:len(dataset)-1,i])\n",
    "    dataY.append(dataset[1:,1])\n",
    "    dataY.append(dataset[1:,2])\n",
    "    dataX=np.array(list(map(list,zip(*dataX))))\n",
    "    dataX=scaler.fit_transform(dataX)\n",
    "    dataX=dataX[:,np.newaxis,:]\n",
    "    dataY=np.array(list(map(list,zip(*dataY))))\n",
    "    dataY=scaler.fit_transform(dataY)\n",
    "    return dataX, dataY\n",
    "\n",
    "def create_model(trainX,trainY,look_back=1):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(36,input_shape=(look_back,trainX.shape[2]),activation=\"sigmoid\",return_sequences=True))\n",
    "    model.add(keras.layers.Dropout(0.1))\n",
    "    model.add(keras.layers.LSTM(36,input_shape=(look_back,trainX.shape[2]),activation=\"sigmoid\",return_sequences=True))\n",
    "    model.add(keras.layers.LSTM(18,input_shape=(look_back,trainX.shape[2]),activation=\"sigmoid\",return_sequences=True))\n",
    "    model.add(keras.layers.LSTM(trainY.shape[1], input_shape=(look_back, trainX.shape[2]),activation=\"sigmoid\"))\n",
    "    #model.add(keras.layers.Dropout(0.1))\n",
    "    model.add(keras.layers.Dense(trainY.shape[1]))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "df = parse('D:\\\\UT Courses\\\\EE 364D\\\\Office\\\\run/eplusout.sql')\n",
    "df.head()\n",
    "dataset=df.values\n",
    "names=df.columns.values.tolist()\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(dataset, names,scaler, look_back)\n",
    "\n",
    "df1 = parse('D:\\\\UT Courses\\\\EE 364D\\\\Office1\\\\run/eplusout.sql')\n",
    "df1.head()\n",
    "testset = df1.values\n",
    "\n",
    "names1=df1.columns.values.tolist()\n",
    "testX, testY = create_dataset(testset, names1,scaler, look_back)\n",
    "\n",
    "model=create_model(trainX,trainY)\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "score, acc = model.evaluate(testX, testY, batch_size=10)\n",
    "print('Test accuracy:', acc)\n",
    "testPredict = model.predict(testX)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY=scaler.inverse_transform(testY)\n",
    "print(testPredict)\n",
    "print(testY)\n",
    "rmse = sqrt(mean_squared_error(testPredict,testY))\n",
    "print(rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
